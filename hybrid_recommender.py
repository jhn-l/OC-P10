import os
import pandas as pd
import numpy as np
import pickle
import boto3
import logging
import matplotlib.pyplot as plt
from surprise import Dataset, Reader, SVD
from surprise.model_selection import train_test_split
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.decomposition import PCA
from sklearn.preprocessing import MinMaxScaler

# ğŸ“Œ Chemins des fichiers
S3_BUCKET_NAME = "my-recommender-dataset"  # âš ï¸ Remplace par ton vrai nom de bucket
CLICKS_FOLDER = "/tmp/clicks/"  # AWS Lambda ne permet l'Ã©criture que dans /tmp/
ARTICLES_METADATA_PATH = "/tmp/articles_metadata.csv"
EMBEDDINGS_PATH = "/tmp/articles_embeddings.pickle"
MODEL_PATH = "/tmp/recommender_model_hybrid.pkl"
DYNAMODB_TABLE = "UserRecommendations"
dynamodb = boto3.resource("dynamodb")

# ğŸ“Œ Charger les interactions utilisateur-article
def load_interactions():
    print("ğŸ”¹ Chargement des interactions utilisateur-article...")
    all_files = [os.path.join(CLICKS_FOLDER, f) for f in os.listdir(CLICKS_FOLDER) if f.startswith("clicks_hour_") and f.endswith(".csv")]
    df_list = [pd.read_csv(f) for f in all_files]
    interactions_df = pd.concat(df_list, ignore_index=True)
    interactions_df.rename(columns={"click_article_id": "article_id"}, inplace=True)
    interactions_df["article_id"] = interactions_df["article_id"].astype(int)
    print("âœ… Interactions chargÃ©es - Nombre de lignes:", interactions_df.shape[0])
    return interactions_df

# ğŸ“Œ EntraÃ®ner le modÃ¨le de filtrage collaboratif
def train_collaborative_model(interactions_df):
    print("ğŸ”¹ PrÃ©paration des donnÃ©es pour Surprise...")
    reader = Reader(rating_scale=(1, 5))
    surprise_data = Dataset.load_from_df(interactions_df[["user_id", "article_id", "session_size"]], reader)
    
    print("ğŸ”¹ EntraÃ®nement du modÃ¨le SVD...")
    trainset, _ = train_test_split(surprise_data, test_size=0.2)
    model = SVD()
    model.fit(trainset)

    print(f"âœ… Sauvegarde du modÃ¨le dans {MODEL_PATH}...")
    with open(MODEL_PATH, "wb") as f:
        pickle.dump(model, f)
    
    upload_model_to_s3()
    print("ğŸš€ ModÃ¨le entraÃ®nÃ© et sauvegardÃ© avec succÃ¨s !")
    return model

# ğŸ“Œ Upload du modÃ¨le vers S3
def upload_model_to_s3():
    s3_client = boto3.client("s3")
    model_filename = "recommender_model_hybrid.pkl"
    print(f"ğŸš€ Upload du modÃ¨le vers S3: {S3_BUCKET_NAME}/{model_filename}...")
    s3_client.upload_file(MODEL_PATH, S3_BUCKET_NAME, model_filename)
    print("âœ… ModÃ¨le uploadÃ© avec succÃ¨s sur S3 !")

# ğŸ“Œ Charger le modÃ¨le depuis S3
def load_model_from_s3():
    s3_client = boto3.client("s3")
    model_filename = "recommender_model_hybrid.pkl"
    local_path = MODEL_PATH
    
    print(f"ğŸ”„ TÃ©lÃ©chargement du modÃ¨le depuis S3...")
    s3_client.download_file(S3_BUCKET_NAME, model_filename, local_path)
    
    with open(local_path, "rb") as f:
        model = pickle.load(f)
    print("âœ… ModÃ¨le chargÃ© avec succÃ¨s depuis S3")
    return model

# ğŸ“Œ Sauvegarder les recommandations dans DynamoDB
def save_recommendations_to_dynamodb(user_id, recommendations):
    print(f"ğŸ’¾ Sauvegarde des recommandations pour l'utilisateur {user_id} dans DynamoDB...")
    table = dynamodb.Table(DYNAMODB_TABLE)
    table.put_item(
        Item={
            "user_id": str(user_id),
            "recommendations": recommendations
        }
    )
    print("âœ… Recommandations sauvegardÃ©es avec succÃ¨s dans DynamoDB")

# ğŸ“Œ Fonction Lambda
def lambda_handler(event, context):
    user_id = event.get("user_id")
    if not user_id:
        return {"statusCode": 400, "body": "{\"error\": \"user_id is required\"}"}
    
    interactions_df = load_interactions()
    model = load_model_from_s3()
    recommendations = train_collaborative_model(interactions_df)
    save_recommendations_to_dynamodb(user_id, recommendations)
    
    return {
        "statusCode": 200,
        "body": "{\"user_id\": " + str(user_id) + ", \"recommendations\": " + str(recommendations) + "}"
    }
